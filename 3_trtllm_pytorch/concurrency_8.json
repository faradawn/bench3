{"date": "20251207-003503", "backend": "openai", "model_id": "meta-llama/Meta-Llama-3-8B-Instruct", "tokenizer_id": "meta-llama/Meta-Llama-3-8B-Instruct", "num_prompts": 5, "duration": 2.8401075650472194, "completed": 5, "total_input_tokens": 640, "total_output_tokens": 2560, "request_throughput": 1.760496701439852, "request_goodput:": null, "output_throughput": 901.3743111372042, "total_token_throughput": 1126.7178889215054, "user_throughput": 180.75395100268491, "avg_decoded_tokens_per_iter": 1.0, "mean_ttft_ms": 74.92367872036994, "median_ttft_ms": 74.83976287767291, "std_ttft_ms": 1.1791849105392376, "p99_ttft_ms": 76.5903041511774, "mean_tpot_ms": 5.396592536660497, "median_tpot_ms": 5.394320671196932, "std_tpot_ms": 0.0043227080494144185, "p99_tpot_ms": 5.403241929188079, "mean_itl_ms": 5.396595097888706, "median_itl_ms": 5.402568960562348, "std_itl_ms": 0.39496327711979373, "p99_itl_ms": 6.240985044278204, "mean_e2el_ms": 2832.5824649538845, "median_e2el_ms": 2831.945699872449, "std_e2el_ms": 2.7214246685901804, "p99_e2el_ms": 2837.5492748059332, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 8}