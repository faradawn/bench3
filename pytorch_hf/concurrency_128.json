{"date": "20251128-205610", "backend": "openai", "model_id": "meta-llama/Meta-Llama-3-8B-Instruct", "tokenizer_id": "meta-llama/Meta-Llama-3-8B-Instruct", "num_prompts": 640, "duration": 20.18868691602256, "completed": 640, "total_input_tokens": 327680, "total_output_tokens": 81920, "request_throughput": 31.700922534593868, "request_goodput:": null, "output_throughput": 4057.718084428015, "total_token_throughput": 20288.590422140074, "user_throughput": 40.227869239951815, "avg_decoded_tokens_per_iter": 1.0, "mean_ttft_ms": 1348.8818357684067, "median_ttft_ms": 1109.009251522366, "std_ttft_ms": 957.8928410113853, "p99_ttft_ms": 3660.708155272296, "mean_tpot_ms": 16.322056975390815, "median_tpot_ms": 16.4216199727531, "std_tpot_ms": 8.899351092092248, "p99_tpot_ms": 42.851478864272, "mean_itl_ms": 16.322061359510478, "median_itl_ms": 0.05404703551903367, "std_itl_ms": 126.96985561126323, "p99_itl_ms": 213.91459351638335, "mean_e2el_ms": 3421.78307164304, "median_e2el_ms": 3198.5986244981177, "std_e2el_ms": 1044.915608982974, "p99_e2el_ms": 6343.497480292572, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 128}